
## Storage Engineering AI Assistant

This is a Streamlit-based AI assistant for storage engineers and management.  
It uses OpenAI’s GPT models to generate vendor-aware guidance and automation content for common storage engineering tasks.

Supported vendors:
- NetApp ONTAP  
- Pure Storage  
- Dell EMC PowerMax  

Supported use cases include:
- Explain Issue and Error  
- Generate Runbook  
- Generate Incident RCA  
- Capacity Planning  
- Performance Analysis  
- DR Test Planning  
- Storage Migration  
- Generate Ansible Playbook  

The app supports both **English** and **German / Deutsch**.

---

### 1. Features

- **Language-aware UI**: Switch between English and German text in the interface.
- **Management dashboard**: High-level overview of supported vendors, use cases, and estimated time-savings.
- **Storage engineering assistant**:  
  - Select vendor and use case.  
  - Paste incident notes, errors, requirements or automation goals.  
  - Get engineering-grade output in the chosen language.
- **Ansible playbook generation**: Generates production-ready Ansible playbooks for storage tasks, using vendor-specific modules where appropriate.
- **Professional tone**: All model responses are constrained to professional, concise, technical language targeted at experienced storage engineers.

---

### 2. Prerequisites

- **Python**: 3.9+ recommended
- **OpenAI API key**

Python libraries used (install via `pip`):

- `streamlit`
- `openai`

---

### 3. Installation

From the project root (where `engineering_copilot.py` lives):

```bash
pip install streamlit openai python-dotenv
```

If you keep a `requirements.txt`, you can instead run:

```bash
pip install -r requirements.txt
```

---

### 4. Environment Configuration

The app loads environment variables via `python-dotenv`.

1. Create a `.env` file in the project root (same folder as `engineering_copilot.py`).
2. Add your OpenAI API key:

```env
OPENAI_API_KEY=sk-...
```

The app will **stop with an error** if `OPENAI_API_KEY` is not set.

---

### 5. Running the App

From the project root:

```bash
streamlit run ./Storage_Engineering_Copilot/engineering_copilot.py
```

Then open the URL Streamlit prints (usually `http://localhost:8501`) in your browser.

---

### 6. Using the Application

#### Management Dashboard tab

- **View metrics**:  
  - Number of supported vendors  
  - Number of use cases  
  - Audience and demo scope  
- **Understand value**:  
  - “What this solves” bullet list  
  - Typical workflow overview

#### Storage Engineering tab

1. **Select language** in the left sidebar (English / German).
2. **Choose vendor** from the dropdown (NetApp ONTAP, Pure Storage, Dell EMC PowerMax).
3. **Choose use case** (Explain Issue, Generate Runbook, RCA, etc.).
4. **Paste input** (error message, incident description, requirement, or automation goal).
5. Click **Run AI Assistant**.
6. View the generated output in the **“AI Output”** section:
   - For general tasks: rich text explanation or runbook.
   - For Ansible playbook: YAML code block ready for use or adaptation.

All responses are generated by an OpenAI chat model (`gpt-4o-mini`) with a system prompt that enforces professional, technical language in the selected language.

---

### 7. Notes & Limitations

- **Advisory only**: The app is a **demo** and does not execute any storage operations, scripts, or APIs.
- **Validation required**: Output should always be reviewed and validated by a storage engineers before use in production.
- **Vendor modules**: When generating Ansible playbooks, the model is instructed to use appropriate vendor modules (`na_ontap_*`, `purefa_*`, `dellemc_powermax_*`, etc.), but these still require validation and adaptation to your environment.

---

### 8. Customization

- **Adding new use cases**:  
  - Extend the `USE_CASES` list in `engineering_copilot.py`.  
  - Add a corresponding template in the `PROMPT_TEMPLATES` dictionary.
- **Changing vendors**:  
  - Update the `VENDORS` list to include/remove storage platforms.
- **Changing model or behavior**:  
  - Adjust the `model` parameter or the `system_message` in the `ask_llm` function in `prompt.py`.
- **Localization**:  
  - Add or modify keys in the `TRANSLATIONS` dictionary to support more languages or refine wording.

---

### 9. Security & Privacy

- Do **not** paste sensitive production data, credentials, or customer-identifying information into the app.
- Ensure your **OpenAI API key** is kept private and never committed to source control.
- Consider additional security controls (network isolation, input redaction) before using in a real operational environment.
```
